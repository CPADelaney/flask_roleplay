# nyx/core/repo_refactor_pipeline.py
"""
from __future__ import annotations


import asyncio, json, os, subprocess, textwrap
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Callable, Optional
from logic.chatgpt_integration import get_openai_client
from agents import (
    Agent,
    ModelSettings,
    Runner,
    function_tool,
    RunContextWrapper,
    AsyncOpenAI,
    OpenAIResponsesModel
)

import openai
from nyx.creative.agentic_system import AgenticCreativitySystem  # shim to v2.2

# ---------------------------------------------------------------------------
# Issue dataclass
# ---------------------------------------------------------------------------

@dataclass
class Issue:
    path: str
    line: int
    tool: str  # ruff | mypy | bandit
    code: str
    msg: str

# ---------------------------------------------------------------------------
# Static analysis helper
# ---------------------------------------------------------------------------

class StaticAnalyzer:
    def __init__(self, repo_root: str):
        # CORRECTED: Resolve the path to an absolute path here as well
        self.repo_root = Path(repo_root).resolve()

    async def run(self, files: List[Path]) -> List[Issue]:
        issues: List[Issue] = []
        if not files:
            return issues

        # Ensure paths in 'files' are also absolute for consistent comparison
        # (though they likely are already if generated by Path.rglob)
        absolute_files = [p.resolve() for p in files]

        # Now this comparison should work because self.repo_root is absolute
        # and paths in absolute_files are absolute.
        try:
            rels = [str(p.relative_to(self.repo_root)) for p in absolute_files]
        except ValueError as e:
            # Add more debug info if it still fails
            print(f"ValueError during relative_to calculation:")
            print(f"  Repo Root: {self.repo_root}")
            if absolute_files:
                print(f"  First File Path: {absolute_files[0]}")
            print(f"  Error: {e}")
            # Re-raise or handle appropriately
            raise e

        # Run tools using relative paths `rels` and absolute repo_root CWD
        # ruff
        try:
            # ruff check prefers relative paths from the CWD
            r = subprocess.run([
                "ruff", "check", "--format", "json", *rels # Use relative paths for the command
            ], cwd=self.repo_root, text=True, capture_output=True, check=False) # CWD is absolute
            if r.stdout:
                # Ruff output often uses relative paths based on CWD, which is what we want
                for item in json.loads(r.stdout):
                    issues.append(Issue(item["filename"], item["location"]["row"], "ruff", item["code"], item["message"]))
            if r.stderr:
                 print(f"Ruff stderr: {r.stderr}")
        except FileNotFoundError:
            print("Warning: ruff not found.")
            pass
        except json.JSONDecodeError:
             print(f"Warning: Failed to decode ruff JSON output: {r.stdout}")
             pass


        # mypy
        try:
            # mypy also typically works well with relative paths from CWD
            mypy_report_dir = self.repo_root / "_mypy_report" # Use absolute path for report dir
            mypy_report_dir.mkdir(exist_ok=True) # Ensure dir exists
            mypy_report_file = mypy_report_dir / "index.json"

            mypy_cmd = [
                "mypy", "--show-error-codes", "--no-color-output", "--no-error-summary",
                "--json-report", str(mypy_report_dir), # Pass report dir path
                *rels # Pass relative file paths
            ]
            # print(f"Running mypy: {' '.join(mypy_cmd)}") # Debug
            subprocess.run(mypy_cmd, cwd=self.repo_root, text=True, capture_output=True, check=False)

            if mypy_report_file.exists():
                data = json.loads(mypy_report_file.read_text())
                # Mypy error paths might be relative or absolute depending on config,
                # try to make them relative to repo_root if absolute
                for err in data.get("errors", []):
                    err_path_str = err["path"]
                    try:
                        err_path = Path(err_path_str)
                        if err_path.is_absolute():
                            err_path_rel = str(err_path.relative_to(self.repo_root))
                        else:
                            err_path_rel = err_path_str # Assume already relative
                    except ValueError:
                         err_path_rel = err_path_str # Fallback if not relative
                    issues.append(Issue(err_path_rel, err["line"], "mypy", err.get("code", "typing"), err["message"]))
        except FileNotFoundError:
            print("Warning: mypy not found.")
            pass
        except json.JSONDecodeError:
             print(f"Warning: Failed to decode mypy JSON report.")
             pass


        # bandit
        try:
            # bandit -r expects relative paths from CWD
            r = subprocess.run([
                "bandit", "-q", "-f", "json", "-r", *rels # Use relative paths
            ], cwd=self.repo_root, text=True, capture_output=True, check=False) # CWD is absolute
            if r.stdout:
                # Bandit filenames should be relative to the CWD used
                data = json.loads(r.stdout)
                for res in data.get("results", []):
                    issues.append(Issue(res["filename"], res["line_number"], "bandit", res["test_id"], res["issue_text"]))
            if r.stderr:
                 print(f"Bandit stderr: {r.stderr}")
        except FileNotFoundError:
            print("Warning: bandit not found.")
            pass
        except json.JSONDecodeError:
             print(f"Warning: Failed to decode bandit JSON output: {r.stdout}")
             pass


        return issues

# ---------------------------------------------------------------------------
# OpenAI chat.responses helper
# ---------------------------------------------------------------------------


async def call_llm(prompt: str, model: str = "gpt-4o"):
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "<!-- OPENAI_API_KEY not set – returning prompt for debug -->\n" + prompt[:800]
    
    client = AsyncOpenAI(api_key=api_key)
    
    # Create the base parameters
    params = {
        "model": model,
        "input": prompt,
        "instructions": "You are an autonomous repo steward AI that suggests minimal, high‑impact patches."
    }
    
    # Only add temperature for models that support it
    # O-series models (like o4-mini) don't support temperature
    if not model.startswith("o"):
        params["temperature"] = 0.15
        params["top_p"] = 0.9
    
    # Make the API call
    response = await client.responses.create(**params)
    
    # Process the response
    result = ""
    for item in response.output:
        if item.type == "message":
            for content in item.content:
                if content.type == "output_text":
                    result += content.text
    
    return result
  


# ---------------------------------------------------------------------------
# Pipeline orchestrator
# ---------------------------------------------------------------------------

class RepoRefactorPipeline:
    """Run the refactor loop with optional human approval."""

    def __init__(self, repo_root: str = "."):
        # Ensure repo_root is resolved and absolute early
        self.repo_root = Path(repo_root).resolve()
        print(f"Pipeline initialized with repo root: {self.repo_root}") # Debug print
        # Pass the resolved absolute path to subsystems
        self.system = AgenticCreativitySystem(str(self.repo_root)) # Pass as string if needed
        self.static = StaticAnalyzer(str(self.repo_root)) # Pass as string

    async def run(
        self,
        goal: str,
        *,
        approve_callback: Optional[Callable[[str], bool]] = None,
        open_pr: bool = False,
        model: str = "gpt-4o", # Changed default to gpt-4o as o4-mini was used later
    ) -> Dict[str, Any]:
        print("Step 1: Ingesting/Embedding changed files...")
        full_scan = os.getenv("FULL_SCAN", "false").lower() == "true"
        
        # Ensure tracker root is also resolved if it uses relative paths
        try:
            changed = (list(self.system.tracker.root.rglob("*"))
                       if full_scan
                       else self.system.tracker.changed_files())
            
            # Filter out non-file paths if rglob includes directories
            changed = [p for p in changed if p.is_file()]

            print(f"Found {len(changed)} potentially changed files (full_scan={full_scan}).")
            if changed:
                 print(f"  Example changed file: {changed[0]}")

        except Exception as e:
            print(f"Error getting changed files: {e}")
            return {"error": f"Failed to get changed files: {e}"}
            
        # Ensure changed files are absolute paths before passing to static analysis
        changed_absolute = [p.resolve() for p in changed]

        # Check if paths are within repo_root BEFORE analysis
        valid_changed_files = []
        for p in changed_absolute:
            try:
                p.relative_to(self.repo_root) # Test if it's relative
                valid_changed_files.append(p)
            except ValueError:
                 print(f"Warning: Skipping file outside repo root: {p}")
        
        if not valid_changed_files:
             print("No valid changed files found within the repository root to analyze.")
             # Decide how to proceed - maybe return success with no changes?
             # For now, let's try embedding analysis even if static analysis is skipped
             # await self.system.incremental_codebase_analysis() # This might fail if 'changed' was needed

        # Pass only valid files to static analyzer
        print(f"Step 2: Running static analysis on {len(valid_changed_files)} files...")
        issues = await self.static.run(valid_changed_files) # Pass list of Path objects
        issues_md = "\n".join(
            f"- `{i.tool}` {i.path}:{i.line} `{i.code}` {i.msg}" for i in issues[:200] # Use i.path which should be relative now
        ) if issues else "No static analysis issues found."
        print(f"Static analysis found {len(issues)} issues.")

        # Run embedding analysis (assuming it handles its own file discovery or uses 'changed')
        # This might need adjustment based on how AgenticCreativitySystem works
        try:
            print("Running incremental codebase analysis (embeddings)...")
            # Make sure this method uses the resolved self.repo_root if needed
            await self.system.incremental_codebase_analysis() 
            print("Codebase analysis complete.")
        except Exception as e:
            # Log embedding errors but try to continue to LLM call if possible
             print(f"Error during incremental_codebase_analysis (embeddings): {e}")
             # Decide if this is fatal or if we can proceed without embeddings
             # return {"error": f"Embedding analysis failed: {e}"} # Make it fatal for now

        # Step 3: Build prompt + call model
        print("Step 3: Building prompt and calling LLM...")
        base_msg = (
            f"You are the repo steward. Goal: {goal}. "
            "Below are lint issues and context snippets. Suggest concrete patches in unified diff format."
        )
        try:
            # Ensure prepare_prompt uses resolved repo_root if necessary
            prompt = await self.system.prepare_prompt(goal, base_msg + "\n\n## Static Analysis Issues\n" + issues_md, k=6)
        except Exception as e:
            print(f"Error preparing prompt: {e}")
            return {"error": f"Failed to prepare prompt: {e}"}
            
        print(f"Prompt length: {len(prompt)}")
        debug_prompt_path = self.repo_root / "debug_prompt.txt"
        try:
            debug_prompt_path.write_text(prompt, encoding="utf-8")
            print(f"Debug prompt saved to {debug_prompt_path}")
        except Exception as e:
             print(f"Warning: Failed to write debug prompt: {e}")
        
        response = await call_llm(prompt, model=model)
        if response.startswith("<!--"): # Check for error comments
            print(f"LLM call failed: {response}")
            return {"error": f"LLM call failed: {response}", "applied": False}
        print(f"LLM response received ({len(response)} chars).")


        # Step 4: Save suggestion
        print("Step 4: Saving suggestion...")
        patch_path = self.repo_root / "_llm_patch.md"
        try:
            patch_path.write_text(response, encoding="utf-8")
            print(f"Patch suggestion saved to {patch_path}")
            # Ensure storage uses resolved repo_root if necessary
            await self.system.storage.store_content(
                content_type="assessment",
                title=f"Refactor suggestion {datetime.utcnow().isoformat(timespec='seconds')}",
                content=response,
                metadata={"goal": goal, "issues": len(issues)},
            )
            print("Suggestion stored in DB.")
        except Exception as e:
            print(f"Error saving suggestion: {e}")
            # Continue to approval gate if possible, but log error
            # return {"error": f"Failed to save suggestion: {e}", "applied": False}


        # Step 5: Approval gate
        print("Step 5: Approval gate...")
        approved = False
        if approve_callback:
            try:
                approved = approve_callback(response)
                print(f"Approve callback result: {approved}")
            except Exception as e:
                print(f"Error in approve_callback: {e}")
                approved = False # Treat callback error as non-approval
        else:
             print("No approve_callback provided, suggestion not auto-approved.")


        if not approved:
            if open_pr:
                print("Opening draft PR with suggestion...")
                try:
                    await self._open_draft_pr(goal, patch_path)
                    print("Draft PR opened.")
                    return {"issues": len(issues), "chars": len(response), "applied": False, "pr_opened": True}
                except Exception as e:
                     print(f"Failed to open draft PR: {e}")
                     return {"issues": len(issues), "chars": len(response), "applied": False, "pr_opened": False, "error": f"Failed to open draft PR: {e}"}
            else:
                print("Suggestion not approved and --pr not specified.")
                return {"issues": len(issues), "chars": len(response), "applied": False, "pr_opened": False}

        # Step 6: Apply patch & run tests
        print("Step 6: Applying patch and running tests...")
        try:
            # Use absolute path for patch_path just in case CWD changes unexpectedly
            patch_abs_path = str(patch_path.resolve())
            apply_cmd = ["git", "apply", patch_abs_path]
            print(f"Running: {' '.join(apply_cmd)} in {self.repo_root}")
            result = subprocess.run(apply_cmd, cwd=self.repo_root, check=True, text=True, capture_output=True)
            print(f"Git apply stdout: {result.stdout}")
            print(f"Git apply stderr: {result.stderr}")
            print("Patch applied successfully.")
        except subprocess.CalledProcessError as exc:
            print(f"git apply failed!")
            print(f"  Return Code: {exc.returncode}")
            print(f"  Stdout: {exc.stdout}")
            print(f"  Stderr: {exc.stderr}")
            # Attempt to provide more context about the failure
            reject_path = self.repo_root / (patch_path.name + ".rej")
            if reject_path.exists():
                 print(f"  Rejection details might be in: {reject_path}")
            return {"error": f"git apply failed (see logs for details)", "applied": False}
        except Exception as e:
            print(f"Unexpected error during git apply: {e}")
            return {"error": f"Unexpected error during git apply: {e}", "applied": False}


        print("Running tests (pytest -q)...")
        test_result = subprocess.run(["pytest", "-q"], cwd=self.repo_root)
        tests_ok = test_result.returncode == 0
        print(f"Tests {'passed' if tests_ok else 'failed'} (return code: {test_result.returncode}).")

        if not tests_ok:
            print("Reverting patch due to failed tests...")
            try:
                # Use absolute path again for robustness
                revert_cmd = ["git", "apply", "-R", patch_abs_path]
                print(f"Running: {' '.join(revert_cmd)} in {self.repo_root}")
                subprocess.run(revert_cmd, cwd=self.repo_root, check=True)
                print("Patch reverted.")
            except Exception as e:
                 print(f"ERROR: Failed to revert patch after failed tests: {e}")
                 # This is problematic, repo might be left in a bad state
            return {"issues": len(issues), "chars": len(response), "applied": False, "tests": "failed"}

        # Step 7: Commit and Push (only if tests passed)
        print("Step 7: Committing changes and handling PR...")
        branch = f"auto/refactor-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        try:
            subprocess.run(["git", "checkout", "-b", branch], cwd=self.repo_root, check=True)
            subprocess.run(["git", "add", "-u"], cwd=self.repo_root, check=True) # Stage changes from applied patch
            subprocess.run(["git", "add", str(patch_path.resolve())], cwd=self.repo_root, check=True) # Add the patch file itself
            subprocess.run(["git", "commit", "-m", f"Automated refactor: {goal}\n\nApplied patch based on LLM suggestion."], cwd=self.repo_root, check=True)
            print(f"Committed changes to branch {branch}")

            if open_pr:
                print("Pushing branch and creating PR...")
                subprocess.run(["git", "push", "-u", "origin", branch], cwd=self.repo_root, check=True)
                # Use --body-file to include patch content in PR description
                subprocess.run([
                    "gh", "pr", "create",
                    "--title", f"Automated Refactor: {goal}",
                    "--body-file", str(patch_path.resolve()), # Use patch content for body
                    "--head", branch
                ], cwd=self.repo_root, check=True)
                print("PR created.")
            else:
                print("--pr not specified, skipping push and PR creation.")

        except subprocess.CalledProcessError as exc:
            print(f"Error during git commit/push/PR: {exc}")
            # Consider reverting commit or branch creation?
            return {"error": f"Git operation failed: {exc}", "applied": True, "tests": "passed", "pr_opened": False}
        except FileNotFoundError:
            print("Error: 'gh' command not found. Cannot create PR automatically.")
            return {"error": "'gh' command not found", "applied": True, "tests": "passed", "pr_opened": False}
        except Exception as e:
            print(f"Unexpected error during commit/push/PR: {e}")
            return {"error": f"Unexpected error during commit/push/PR: {e}", "applied": True, "tests": "passed", "pr_opened": False}

        # Clean up patch file? Optional.
        # patch_path.unlink(missing_ok=True)

        print("Pipeline completed successfully.")
        return {"issues": len(issues), "chars": len(response), "applied": True, "tests": "passed", "pr_opened": bool(open_pr), "branch": branch}

    async def _open_draft_pr(self, goal: str, patch_file: Path):
        """Helper to open a draft PR with the suggestion"""
        branch = f"auto/refactor-suggestion-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
        try:
            # Ensure we are on the original branch before creating a new one
            # current_branch = subprocess.check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"], cwd=self.repo_root, text=True).strip()
            # print(f"Current branch: {current_branch}") # Debug

            # Use git switch -c which handles creating new branch cleanly
            subprocess.run(["git", "switch", "-c", branch], cwd=self.repo_root, check=True)
            print(f"Switched to new branch: {branch}")

            # Stage and commit ONLY the patch file
            subprocess.run(["git", "add", str(patch_file.resolve())], cwd=self.repo_root, check=True)
            commit_msg = f"draft: LLM Refactor Suggestion\n\nGoal: {goal}\n\nContains proposed changes in _{patch_file.name}"
            subprocess.run(["git", "commit", "-m", commit_msg], cwd=self.repo_root, check=True)
            print("Committed suggestion patch file.")

            # Push the new branch
            subprocess.run(["git", "push", "-u", "origin", branch], cwd=self.repo_root, check=True)
            print("Pushed suggestion branch.")

            # Create the draft PR
            pr_title = f"Draft Suggestion: {goal}"
            pr_body = f"LLM-generated refactoring suggestion for goal: '{goal}'.\n\nPlease review the attached patch file (`{patch_file.name}`) and approve or reject.\n\n_(This is a draft PR containing only the suggestion, not the applied code changes.)_"
            subprocess.run([
                "gh", "pr", "create",
                "--title", pr_title,
                "--body", pr_body,
                "--head", branch,
                "--draft"
            ], cwd=self.repo_root, check=True)
            print("Draft PR created.")

            # Switch back to the original branch (important!)
            # It's safer to handle this outside this function, in the main run flow after calling this.
            # Or pass the original branch name to switch back to.
            # For now, let's assume the caller handles switching back.

        except subprocess.CalledProcessError as exc:
            print(f"Error opening draft PR (branch: {branch}): {exc}")
            print(f"  Stderr: {exc.stderr}")
            # Consider cleaning up the branch?
            # subprocess.run(["git", "checkout", original_branch], cwd=self.repo_root) # Switch back
            # subprocess.run(["git", "branch", "-D", branch], cwd=self.repo_root) # Delete local
            # subprocess.run(["git", "push", "origin", "--delete", branch], cwd=self.repo_root) # Delete remote
            raise # Re-raise the exception so the caller knows it failed
        except FileNotFoundError:
            print("Error: 'gh' command not found. Cannot create draft PR automatically.")
            raise # Re-raise
        except Exception as e:
            print(f"Unexpected error during draft PR creation: {e}")
            raise # Re-raise

            

# ---------------------------------------------------------------------------
# CLI helper (non‑interactive)
# ---------------------------------------------------------------------------

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("goal", help="High‑level refactor goal, e.g. 'improve db layer'")
    parser.add_argument("--pr", action="store_true", help="Open GitHub draft PR with suggestion")
    args = parser.parse_args()

    asyncio.run(RepoRefactorPipeline().run(args.goal, open_pr=args.pr))

class ContextAwareRepoRefactorPipeline(ContextAwareModule):
    """
    Minimal A2A integration for repo refactoring - mainly for reporting
    """
    
    def __init__(self, original_pipeline):
        super().__init__("repo_refactor")
        self.original_pipeline = original_pipeline
        self.context_subscriptions = [
            "development_request", "code_analysis_request"
        ]
    
    async def on_context_received(self, context: SharedContext):
        """Initialize refactor context"""
        logger.debug("RepoRefactor received context")
        
        # This module doesn't process regular user interactions
        if context.task_purpose != "development":
            return
        
        await self.send_context_update(
            update_type="refactor_ready",
            data={"status": "ready", "capabilities": ["analysis", "refactoring"]},
            priority=ContextPriority.LOW
        )
    
    async def on_context_update(self, update: ContextUpdate):
        """Handle development-related updates"""
        if update.update_type == "code_analysis_request":
            goal = update.data.get("goal", "improve code quality")
            # This would typically be run separately, not in regular interaction
            logger.info(f"Refactor request received: {goal}")
    
    async def process_input(self, context: SharedContext) -> Dict[str, Any]:
        """Not used for regular processing"""
        return {"processed": False, "reason": "development_tool"}
    
    async def process_analysis(self, context: SharedContext) -> Dict[str, Any]:
        """Not used for regular processing"""
        return {"analyzed": False, "reason": "development_tool"}
    
    async def process_synthesis(self, context: SharedContext) -> Dict[str, Any]:
        """Not used for regular processing"""
        return {"synthesized": False, "reason": "development_tool"}
    
    def __getattr__(self, name):
        return getattr(self.original_pipeline, name)
"""

